Machine Learning Project â€“ Postgraduate Studies (Machine Learning)
Author: RadosÅ‚aw

---------------------------------------------

ðŸŽ¯ Project Goal

The objective of this project is to build a machine learning model capable of classifying news headlines as either:

- Fake (1)
- Real (0)

The task is performed purely on the headline text.  
This makes the problem both interesting and challenging due to limited textual context.

The project uses classical NLP + ML methods (TF-IDF + linear models), following academic requirements.

---------------------------------------------

ðŸ“‚ Project Structure

project/
â”‚   
  â”œâ”€â”€ main.py                 # Full pipeline orchestration

  â”œâ”€â”€ eda.py                  # Exploratory Data Analysis

  â”œâ”€â”€ utils.py                # Preprocessing utilities

  â”œâ”€â”€ train_baseline.py       # Baseline Logistic Regression

  â”œâ”€â”€ train_models.py         # Additional ML models

  â”œâ”€â”€ train_optuna.py         # Hyperparameter tuning

  â”œâ”€â”€ evaluate.py             # Evaluation metrics

  â”œâ”€â”€ interpretation.py       # SHAP + WordCloud and explanations

  â”œâ”€â”€ predict.py              # Model inference (new headline prediction)

  â”œâ”€â”€ data/
   â””â”€â”€ final_dataset.csv   # Cleaned dataset (ignored in git)

  â”œâ”€â”€ models/                 # Saved ML models (.pkl)

  â”œâ”€â”€ plots/                  # EDA + SHAP plots
  
  â””â”€â”€ README.md



---------------------------------------------

ðŸ”§ Technologies Used

Python 3.12  
Pandas, NumPy  
scikit-learn  
Optuna  
NLTK  
Matplotlib, Seaborn, WordCloud  
SHAP  
Joblib  

---------------------------------------------

ðŸ§¹ Preprocessing

- Lowercasing text  
- Removing HTML tags  
- Removing URLs  
- Removing non-alphabetic characters  
- Tokenization  
- Stopword removal  
- Removing extremely short or long titles  
- Removing duplicates  

Final dataset size: ~62k headlines.

---------------------------------------------

ðŸ“Š Exploratory Data Analysis (EDA)

Includes:

- Class distribution  
- Word frequency comparison  
- WordClouds  
- Title length histograms  
- Outlier removal  

Plots saved in /plots.

---------------------------------------------

ðŸ¤– Models Trained

Baseline: Logistic Regression  
- TF-IDF (1â€“2 ngrams)  
- F1 â‰ˆ 0.888  
- AUC â‰ˆ 0.96  

Other models:
- Linear SVM  
- Random Forest  
- Naive Bayes  

Hyperparameter tuning with Optuna:
- LogisticRegression  
- Linear SVM  

Best model:
- SVM F1 â‰ˆ 0.891  
- AUC â‰ˆ 0.963  

---------------------------------------------

ðŸ§ª Final Model Performance (Test Set)

Accuracy: 0.90  
Precision: 0.89  
Recall: 0.89  
F1-score: 0.888â€“0.891  
AUC: 0.963  

Confusion matrix, ROC curve, classification report generated automatically.

---------------------------------------------

ðŸ§  Interpretation

Includes:

- WordCloud  
- Frequent words  
- SHAP (LinearExplainer + TF-IDF)  
- Wrong predictions exported to CSV  

---------------------------------------------

ðŸš€ Running the Full Pipeline

python main.py

---------------------------------------------

ðŸ”® Prediction on New Titles

from predict import load_predictor  
model = load_predictor()  
result = model.predict("BREAKING: Obama admits something shocking")  

Output example:

input: "BREAKING: Obama admits something shocking"  
prediction: 1  
is_fake: true  
probability: 0.91  

---------------------------------------------

ðŸ“Œ Notes for Academic Review

Includes:

- Data loading  
- EDA  
- Preprocessing  
- Baseline  
- Multiple models  
- Metrics  
- ROC, confusion matrix  
- Optuna tuning  
- Interpretation  
- No notebooks â€” modular Python code  

---------------------------------------------

ðŸ™‹ RadosÅ‚aw 

